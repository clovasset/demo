import streamlit as st
import requests
from bs4 import BeautifulSoup
import time
import json

# API í´ë˜ìŠ¤ ì •ì˜


class CompletionExecutor:
    def __init__(self, host, api_key, api_key_primary_val, request_id):
        self._host = host
        self._api_key = api_key
        self._api_key_primary_val = api_key_primary_val
        self._request_id = request_id

    def execute(self, completion_request):
        headers = {
            'X-NCP-CLOVASTUDIO-API-KEY': self._api_key,
            'X-NCP-APIGW-API-KEY': self._api_key_primary_val,
            'X-NCP-CLOVASTUDIO-REQUEST-ID': self._request_id,
            'Content-Type': 'application/json; charset=utf-8',
            'Accept': 'text/event-stream'
        }

        with requests.post(self._host + '/testapp/v1/tasks/iqsmk52h/chat-completions',
                           headers=headers, json=completion_request, stream=True) as r:
            event_stream_data = []
            for line in r.iter_lines():
                if line:
                    event_stream_data.append(line.decode("utf-8"))
            return event_stream_data

# ìŠ¤íŠ¸ë¦¼ íŒŒì‹± í•¨ìˆ˜ ì •ì˜


def parse_event_stream(stream):
    last_message_content = None
    for line in stream:
        if line.startswith("data:"):
            data = json.loads(line[len("data:"):])
            if "message" in data and "content" in data["message"]:
                last_message_content = data["message"]["content"]
    return last_message_content


# ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë¡¤ë§í•˜ëŠ” í•¨ìˆ˜
def get_search_results(keyword):
    response = requests.get(
        f"https://search.naver.com/search.naver?where=news&sm=tab_jum&query={keyword}&sort=0&pd=1d")
    html = response.text
    soup = BeautifulSoup(html, "html.parser")
    return soup.select("div.info_group")

# ê°œë³„ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ í¬ë¡¤ë§í•˜ëŠ” í•¨ìˆ˜


def get_article_details(url):
    response = requests.get(url, headers={'User-agent': 'Mozilla/5.0'})
    html = response.text
    soup = BeautifulSoup(html, "html.parser")

    if "entertain" in response.url:
        title = soup.select_one(".end_tit")
        content = soup.select_one("#articeBody")
    elif "sports" in response.url:
        title = soup.select_one("h4.title")
        content = soup.select_one("#newsEndContents")
        divs = content.select("div")
        for div in divs:
            div.decompose()
        paragraphs = content.select("p")
        for p in paragraphs:
            p.decompose()
    else:
        title = soup.select_one(".media_end_head_headline")
        content = soup.select_one("#dic_area")

    return title.text.strip(), content.text.strip()

# ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í•¨ìˆ˜


def collect_news_data(keyword):
    articles = get_search_results(keyword)
    titles = []
    contents = []
    links = []

    for i, article in enumerate(articles):
        if i >= 3:
            break
        links_in_article = article.select("a.info")
        if len(links_in_article) >= 2:
            url = links_in_article[1].attrs["href"]
            title, content = get_article_details(url)
            titles.append(title)
            contents.append(content)
            links.append(url)
            time.sleep(0.3)

    return titles, contents, links

#######################################################################################################
# Streamlit ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜


def main():
    st.title("ì£¼ì‹ í€´ì¦ˆ ìƒì„±ê¸°")

    keyword = st.text_input("ë³´ìœ  ì¢…ëª©:", value="", placeholder="ë³´ìœ  ì¢…ëª©ì„ ì…ë ¥í•˜ì„¸ìš”",
                            key='keyword_input', label_visibility="collapsed")

    col1, col2, col3, col4 = st.columns([1, 1, 1, 1])
    with col1:
        blank = []
    with col2:
        age = st.number_input("íˆ¬ìì ë‚˜ì´:", min_value=0, max_value=120, value=25)
    with col3:
        year = st.number_input("íˆ¬ìê²½ë ¥(ë…„):", min_value=0, max_value=100, value=1)
    with col4:
        blank = []

    if keyword:
        with st.spinner('ë‰´ìŠ¤ ì½ëŠ”ì¤‘..ğŸ“°'):
            titles, contents, links = collect_news_data(keyword)
            if contents:
                articles_content = " ".join(contents)
                st.success("ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ì œëª©")
                for i in titles:
                    st.write(i)

                preset_text = [
                    {
                        "role": "system",
                        "content": (
                            "ë„ˆëŠ” ì‚¬ìš©ìê°€ ì£¼ëŠ” ìµœì‹  ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ë‚´ìš©ì„ ì·¨í•©í•´ ì‚¬ìš©ìì—ê²Œ ì£¼ì‹ íˆ¬ì êµìœ¡ ì œê³µì„ ëª©ì ìœ¼ë¡œ í€´ì¦ˆë¥¼ ë§Œë“¤ì–´ì¤„ê±°ì•¼."
                            "\ní€´ì¦ˆëŠ” ì‚¬ìš©ìê°€ ì£¼ëŠ” ìµœì‹ ê¸°ì‚¬ ë‚´ìš©ì—ì„œ ì£¼ì‹ ê°€ê²©ì— ì˜í–¥ì„ ì¤„ ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ, ì‚¬ìš©ìì˜ ë³´ìœ ì¢…ëª©ì— ê´€í•´ì„œ ë‚´ì¤˜."
                            "\n4ì§€ì„ ë‹¤ì— ì •ë‹µì€ 1ê°œì¸ í€´ì¦ˆì´ê³ , ë”± 1ê°œì˜ í€´ì¦ˆë§Œ ë§Œë“¤ë©´ ë¼."
                            "\nì•„ë˜ì— ë„ˆê°€ í•´ì•¼í•˜ëŠ” ë‹µë³€ì˜ í˜•ì‹ì„ ì§€ì •í•´ì¤„ê²Œ. ì—¬ê¸° ~~~ë¶€ë¶„ì— ë„ˆì˜ ë‹µë³€ì„ ë„£ì–´ì£¼ë©´ ë¼."
                            "\n\n[ë‹µë³€ í˜•ì‹]\nì˜¤ëŠ˜ì˜ ì§ˆë¬¸ :~~~? \n1.~~~\n2.~~~\n3.~~~\n4.~~~\n\nì •ë‹µ :~~~ë²ˆ ~~~\n\ní•´ì„¤ :~~~"
                        )
                    },
                    {
                        "role": "user",
                        "content": f"{articles_content}\në‚˜ì´: {age}ì„¸\níˆ¬ìê²½ë ¥: {year}ë…„\në³´ìœ ì¢…ëª©: {keyword}"
                    }
                ]

                request_data = {
                    'messages': preset_text,
                    'topP': 0.8,
                    'topK': 0,
                    'maxTokens': 256,
                    'temperature': 0.5,
                    'repeatPenalty': 5.0,
                    'stopBefore': [],
                    'includeAiFilters': True,
                    'seed': 0
                }

                completion_executor = CompletionExecutor(
                    host='https://clovastudio.stream.ntruss.com',
                    api_key='NTA0MjU2MWZlZTcxNDJiY45r/DkTDk7oBmqKVrH2tgppYRF/3kCtv0bwtT7ihqUM',
                    api_key_primary_val='2vb3PzZVsMZcjwGY1yQG7xbuK0FqU7hrFGli34ou',
                    request_id='5dab9fa6-5425-4ae9-974f-9176bfe755d6'
                )

                with st.spinner('í€´ì¦ˆ ìƒì„±ì¤‘..ğŸ§'):
                    event_stream_data = completion_executor.execute(
                        request_data)
                    response = parse_event_stream(event_stream_data)
                    st.success("í€´ì¦ˆ ìƒì„±ì™„ë£Œâœ”")
                    st.write(response)


if __name__ == "__main__":
    main()
